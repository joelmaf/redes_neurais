{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8K70Mebuy5W"
      },
      "source": [
        "# Problema:  Prever se um cliente vai cancelar sua assinatura"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YaS8AiWY2XZ"
      },
      "source": [
        "# Estrutura das variáveis\n",
        "\n",
        "\n",
        "*   **Estado:** O estado de onde o cliente é originário\n",
        "*   **Tempo de conta:** Número de dias que o cliente está usando os serviços\n",
        "*   **Código de área:** A área de onde o cliente é originário\n",
        "*   **Número de telefone:** O número de telefone do cliente\n",
        "*   **Plano internacional:** O status do plano internacional do cliente\n",
        "*   **Plano de correio de voz:** O status do plano de correio de voz do cliente\n",
        "*   **Número de mensagens de correio de voz:** Número de mensagens de correio de voz enviadas pelo cliente\n",
        "*   **Total de minutos diurnos:** Total de minutos de chamadas feitos por um cliente durante o dia\n",
        "*   **Total de chamadas diurnas:** Número total de chamadas feitas por um cliente durante o dia\n",
        "*   **Total de cobranças diurnas:** Valor total cobrado a um cliente **durante** o dia\n",
        "*   **Total de minutos vespertinos:** Total de minutos de chamadas feitos por um cliente durante a tarde\n",
        "*   **Total de chamadas vespertinas:** Número total de chamadas feitas por um cliente durante a tarde\n",
        "*   **Total de cobranças vespertinas:** Valor total cobrado a um cliente durante a tarde\n",
        "*   **Total de minutos noturnos:** Total de minutos de chamadas feitos por um cliente durante a noite\n",
        "*   **Total de chamadas noturnas:** Número total de chamadas feitas por um cliente durante a noite\n",
        "*   **Total de cobranças noturnas:** Valor total cobrado a um cliente durante a noite\n",
        "*   **Total de minutos internacionais:** Total de minutos de chamadas internacionais feitas por um cliente\n",
        "*   **Total de chamadas internacionais:** Número total de chamadas internacionais feitas por um cliente\n",
        "*   **Total de cobranças internacionais:** Valor total cobrado por chamadas internacionais feitas por um cliente\n",
        "*   **Chamadas ao serviço de atendimento ao cliente:** Número total de chamadas feitas ao serviço de atendimento ao cliente\n",
        "*   **Cancelamento:** Cancelado ou não\n",
        "\n",
        "https://github.com/kuldeep1909/Sony-Research-Machine-Learning-Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms46HPyxlXSp"
      },
      "outputs": [],
      "source": [
        "#!pip install pandas\n",
        "#!pip install numpy\n",
        "#!pip install matplotlib\n",
        "#!pip install seaborn\n",
        "#!pip install scikit-learn\n",
        "#!pip install jupyter\n",
        "!pip install shap\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUmWnZ_FYdL8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchmetrics\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from imblearn.over_sampling import ADASYN\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DE4dlmH3lzBf"
      },
      "outputs": [],
      "source": [
        "url = 'Sony_data.csv'\n",
        "df = pd.read_csv(url)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEguwQvpl6R8"
      },
      "source": [
        "## Análise Exploratória dos Dados (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJobmlj-rsBB"
      },
      "source": [
        "#### Atributo shape\n",
        "\n",
        "O atributo **shape** em um DataFrame do pandas retorna uma tupla com o **número de linhas e colunas** do DataFrame, ou seja, a dimensão do DataFrame. O primeiro valor da tupla indica o número de linhas e o segundo valor indica o número de colunas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypyXfyvzl5U3"
      },
      "outputs": [],
      "source": [
        "# Análise dos registros e features\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra1scQ_SsDwW"
      },
      "source": [
        "#### Método info()\n",
        "\n",
        "O método **info()** no pandas exibe um **resumo conciso** sobre o DataFrame. Esse método é útil para obter uma visão geral da estrutura do DataFrame, especialmente para **verificar rapidamente quais colunas têm valores nulos e quais tipos de dados** estão presentes.\n",
        "\n",
        "Ele fornece as seguintes informações:\n",
        "\n",
        "*   Número total de entradas (linhas) no DataFrame.\n",
        "*   Nome das colunas do DataFrame.\n",
        "*   Número total de valores não nulos para cada coluna.\n",
        "*   Tipo de dado (dtype) de cada coluna, como int64, float64, object, etc.\n",
        "*   Uso de memória do DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRokzOK8mIei"
      },
      "outputs": [],
      "source": [
        "# Análise dos tipos de dados\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19fRvhb3tMrm"
      },
      "source": [
        "#### Comando isna().sum()\n",
        "\n",
        "O comando **isna().sum()** no pandas é utilizado para verificar a quantidade de valores nulos (ou ausentes) em cada coluna de um DataFrame.\n",
        "\n",
        "* isna(): cria um DataFrame booleano, onde cada célula indica True se o valor for nulo (NaN), ou False se o valor não for nulo.\n",
        "* sum(): Ao aplicar o sum() após isna(), ele conta o número de valores True (ou seja, valores nulos) em cada coluna.  O **resultado será uma série (Series)** que mostra o nome de cada coluna e o número de valores nulos correspondentes.\n",
        "* reset_index(): Converte a série resultante em um DataFrame. O índice original (nomes das colunas) é transformado em uma coluna normal.\n",
        "* rename(columns={...}): Renomeia as colunas do DataFrame resultante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V87xEJHDmIiM"
      },
      "outputs": [],
      "source": [
        "# Análise dos valores nulos\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#A coluna index (o nome padrão criado pelo reset_index()) é renomeada\n",
        "#para \"Features\", e a coluna com a contagem de nulos é renomeada para \"Count\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUVOdeaUzeM3"
      },
      "source": [
        "#### <p style=\"color:blue;\">Comando duplicated().sum()</p>\n",
        "\n",
        "O comando **df.duplicated().sum()** no pandas é utilizado para **identificar e contar quantas linhas duplicadas existem** no DataFrame df.\n",
        "\n",
        "* df.duplicated(): Retorna uma série booleana que indica, para cada linha do DataFrame, se ela é uma duplicata ou não. O valor será True se a linha for duplicada em relação a uma linha anterior e False se for única.\n",
        "* sum(): Soma os valores True (que são interpretados como 1), retornando o número total de linhas duplicadas no DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4VHtilumIlo"
      },
      "outputs": [],
      "source": [
        "# Análise dos valores duplicados\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ERERc5W11hA"
      },
      "source": [
        "####  Comando df.describe\n",
        "\n",
        "O comando describe() no pandas é utilizado para **gerar estatísticas descritivas resumidas** das colunas numéricas de um DataFrame.\n",
        "\n",
        "* count: Número de valores não nulos em cada coluna.\n",
        "* mean: A média dos valores em cada coluna.\n",
        "* std: O desvio padrão dos valores em cada coluna, que mede a dispersão dos dados.\n",
        "* min: O valor mínimo de cada coluna.\n",
        "* 25%: O primeiro quartil (25º percentil), que representa o ponto em que 25% dos dados estão abaixo deste valor.\n",
        "* 50% (mediana): O segundo quartil ou mediana (50º percentil), que representa o valor central.\n",
        "* 75%: O terceiro quartil (75º percentil), que representa o ponto em que 75% dos dados estão abaixo deste valor.\n",
        "* max: O valor máximo de cada coluna."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LY2dSp1LmIpK"
      },
      "outputs": [],
      "source": [
        "# Análise das medidas estatísticas (numéricas)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NxtSatg1I8U"
      },
      "source": [
        "O comando describe(include='object') no pandas é usado para **gerar estatísticas descritivas** para as colunas que têm dados de tipo \"objetos\" (normalmente, colunas que contêm strings ou outros tipos categóricos).\n",
        "\n",
        "Quando aplicado a colunas com strings ou dados categóricos, o describe() retorna as seguintes informações:\n",
        "\n",
        "* count: O número de valores não nulos.\n",
        "* unique: O número de valores únicos.\n",
        "* top: O valor mais frequente (moda).\n",
        "* freq: A frequência do valor mais frequente (quantas vezes ele aparece)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCvXmIL9mIsb"
      },
      "outputs": [],
      "source": [
        "# Análise das medidas estatísticas (categóricas)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy0I4FJV2iOt"
      },
      "source": [
        "#### Análise dos Outliers\n",
        "\n",
        "Um outlier (ou valor aberrante) é um ponto de dado que se distancia significativamente dos outros valores de um conjunto de dados. Ele pode indicar uma variação incomum, erro de medição ou entrada incorreta. A Análise dos Outliers tem o objetivo de detectar outliers em colunas numéricas de um DataFrame.\n",
        "\n",
        "Os Outliers são importantes porque:\n",
        "* Indicadores de Problemas: Outliers podem apontar erros de entrada de dados, problemas de medição ou mudanças inesperadas no comportamento de um sistema.\n",
        "* Influência nas Estatísticas: Outliers podem distorcer medidas como a média, desvio padrão e até afetar algoritmos de aprendizado de máquina, que são sensíveis a esses valores extremos.\n",
        "* Análise de Casos Especiais: Em alguns casos, outliers podem ser fenômenos de interesse, como fraudes em sistemas financeiros ou eventos raros em estudos científicos.\n",
        "\n",
        "Um dos método que pode ser utilizado é o médodo do Intervalo Interquartil (IQR).  O IQR é a diferença entre o terceiro quartil (Q3) e o primeiro quartil (Q1).\n",
        "\n",
        "* Valores menores que Q1 - 1.5 * IQR são considerados outliers baixos.\n",
        "* Valores maiores que Q3 + 1.5 * IQR são considerados outliers altos.\n",
        "\n",
        "Outras formas de identificar os outliers:\n",
        "\n",
        "* Método da Desvio Padrão: Qualquer valor que esteja a mais de 2 ou 3 desvios padrão da média poderia ser analisado com sendo um outlier.\n",
        "* Visualizações: gerar Boxplots que mostram a distribuição dos dados e destacam valores fora do intervalo esperado como outliers. Gerar Histogramas que mostram a frequência de valores e podem evidenciar valores que estão distantes da maioria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFxu2qKRmIu8"
      },
      "outputs": [],
      "source": [
        "# Análise dos Outliers: Médodo do Intervalo Interquartil (IQR)\n",
        "def detect_outliers_iqr(df):\n",
        "\n",
        "    #outlier_count armazena o número de outliers para cada coluna\n",
        "    outlier_count = {}\n",
        "    outliers_values = pd.DataFrame()\n",
        "    for column in df.select_dtypes(include='number'):\n",
        "        Q1 = df[column].quantile(0.25)\n",
        "        Q3 = df[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
        "        outliers_values = pd.concat([outliers_values, outliers])\n",
        "        outlier_count[column] = outliers.shape[0]\n",
        "    return outlier_count, outliers_values.drop_duplicates()\n",
        "\n",
        "outliers_count_df, outliers_values_df = detect_outliers_iqr(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsY7SMaq7E77"
      },
      "outputs": [],
      "source": [
        "outliers_count_df  = pd.DataFrame(list(outliers_count_df.items()), columns=['Variáveis', 'Número de Outliers'])\n",
        "outliers_count_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ8L1iDTCG99"
      },
      "outputs": [],
      "source": [
        "variables_with_outliers = outliers_count_df['Variáveis'].tolist()\n",
        "variables_with_outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjiegVLx8iK4"
      },
      "outputs": [],
      "source": [
        "palette = sns.color_palette(\"Set2\")\n",
        "plt.figure(figsize=(12, len(variables_with_outliers) * 4))\n",
        "\n",
        "for i, col in enumerate(variables_with_outliers):\n",
        "    plt.subplot(len(variables_with_outliers), 2, i + 1)\n",
        "    sns.boxplot(data=df[[col]], palette=palette)\n",
        "    plt.title(f'{col}', fontsize=14)\n",
        "    plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4LtQXXP7HFx"
      },
      "outputs": [],
      "source": [
        "outliers_values_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzidDVi8FW0m"
      },
      "source": [
        "#### Análise de classes desbalanceadas\n",
        "\n",
        "A análise de classes desbalanceadas é o processo de examinar a distribuição das classes em um conjunto de dados, particularmente em problemas de classificação, para identificar se há uma disparidade significativa no número de exemplos entre as diferentes classes. Esse desbalanceamento pode impactar a performance de modelos de aprendizado de máquina e é um ponto crítico a ser abordado durante a fase de pré-processamento e modelagem de dados.\n",
        "\n",
        "\n",
        "Em um problema de classificação, as \"classes\" são os diferentes rótulos que o modelo tenta prever. Uma análise simples de classes desbalanceadas, pode ser feita calculando a porcentagem de ocorrência de cada classe em uma coluna. Por exemplo, em um problema de detecção de fraudes, as classes podem ser \"fraude\" e \"não fraude\". Uma classe desbalanceada ocorre quando uma ou mais classes têm muito mais (ou muito menos) exemplos do que outras. Por exemplo, se 95% dos dados forem da classe \"não fraude\" e apenas 5% forem da classe \"fraude\", temos um cenário de desbalanceamento.\n",
        "\n",
        "\n",
        "Classe desbalanceadas podem ter impacto na performance dos modelos de aprendizado de máquina que geralmente são treinados para minimizar um erro geral (como acurácia). Se os dados forem desbalanceados, o modelo pode aprender a ignorar as classes minoritárias, prevendo sempre a classe majoritária, o que pode resultar em um modelo que parece ser preciso, mas que na realidade não resolve o problema.\n",
        "\n",
        "Métricas como acurácia podem ser enganosas em cenários desbalanceados. Um modelo pode parecer \"preciso\" porque acerta a maioria das previsões para a classe majoritária, enquanto falha completamente em identificar a classe minoritária.  Quando os dados são desbalanceados, métricas como F1-score, Precisão, Revocação (Recall) e AUC-ROC tornam-se mais adequadas para avaliação, em vez de acurácia. Essas métricas consideram o desempenho em relação à classe minoritária."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPTtT4_vG2E8"
      },
      "source": [
        "#### Comando value_counts()\n",
        "\n",
        "Conta o número de ocorrências de cada valor na coluna. O argumento normalize=True faz com que o resultado seja a proporção (fração) de cada valor em relação ao total. O resultado é uma série (Series)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvwwYjp9nt91"
      },
      "outputs": [],
      "source": [
        "# Análise das classes desbalanceadas\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UylCgaCmmIxv"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='Cancelamento', data=df, palette='viridis')\n",
        "plt.title('Distribuição do Cancelamento')\n",
        "plt.xlabel('Cancelamento')\n",
        "plt.ylabel('Contagem')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4dSGyP7HSgF"
      },
      "source": [
        "#### Correlação\n",
        "\n",
        "A análise de correlação é um método estatístico utilizado para medir e avaliar a relação entre duas ou mais variáveis. Ela permite identificar se, e em que grau, as variáveis estão relacionadas entre si, ou seja, se a mudança em uma variável está associada a mudanças em outra.\n",
        "\n",
        "Tipos de Correlação:\n",
        "* Correlação Positiva: Quando uma variável aumenta, a outra também tende a aumentar. Exemplo: À medida que a altura de uma pessoa aumenta, o peso também tende a aumentar.\n",
        "* Correlação Negativa: Quando uma variável aumenta, a outra tende a diminuir. Exemplo: À medida que o preço de um produto aumenta, a demanda pode diminuir.\n",
        "Correlação Nula (ou Ausente):\n",
        "* Não há uma relação linear aparente entre as variáveis. Exemplo: A altura de uma pessoa e o número de livros que ela lê por ano provavelmente não estão relacionados.\n",
        "\n",
        "Na fase de análise exploratória de dados (EDA), a correlação é útil para entender as relações entre diferentes variáveis no conjunto de dados.\n",
        "Pode ajudar a identificar variáveis que são redundantes (altamente correlacionadas) e aquelas que podem ser mais úteis para previsão. Variáveis altamente correlacionadas podem conter informações redundantes, o que pode ser prejudicial em certos modelos, como a regressão linear. A correlação pode guiar a eliminação de variáveis correlacionadas para melhorar a performance do modelo.\n",
        "\n",
        "Embora a correlação não implique causalidade, ela pode ser o primeiro passo para identificar relações que merecem investigação mais aprofundada. Por exemplo, se duas variáveis são altamente correlacionadas, pode ser interessante investigar se uma causa a outra, ou se há um terceiro fator envolvido.\n",
        "\n",
        "Medidas de Correlação:\n",
        "\n",
        "* **Correlação de Pearson** Medida mais comum para variáveis numéricas que têm uma relação linear. A correlação de Pearson, em particular, pode ser sensível a outliers, o que pode distorcer a percepção da relação entre as variáveis.Intervalo de valores: entre -1 e 1.\n",
        "\n",
        "  * 1: Correlação positiva perfeita (quando uma variável aumenta, a outra também aumenta de maneira proporcional).\n",
        "  * 0: Nenhuma correlação linear.\n",
        "  * -1: Correlação negativa perfeita (quando uma variável aumenta, a outra diminui de maneira proporcional).\n",
        "* **Correlação de Spearman**: Usada para variáveis que não têm uma relação linear, mas sim uma relação monotônica (onde a ordem dos dados importa). Baseada no ranking das variáveis, sendo útil quando há valores atípicos ou dados não normalmente distribuídos.\n",
        "* **Correlação de Kendall**: Outra medida baseada em ranking, mas usada para avaliar a força de associação entre duas variáveis ordinais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUWa9nA_MBkH"
      },
      "source": [
        "#### Comando select_dtypes\n",
        "\n",
        "Esse comando seleciona as colunas de um DataFrame com base nos seus tipos de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqBJImA4q9k6"
      },
      "outputs": [],
      "source": [
        "numerical_features = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_features = df.select_dtypes(include=['object']).columns\n",
        "categorical_features = categorical_features.drop('Estado')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAs4C8OfMl9L"
      },
      "source": [
        "#### Comando corr(method='pearson')\n",
        "\n",
        "Calcula a matriz de correlação entre as variáveis numéricas usando o coeficiente de correlação de Pearson. O coeficiente de Pearson mede a relação linear entre duas variáveis, retornando um valor entre -1 e 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qU0GRm0XqxHN"
      },
      "outputs": [],
      "source": [
        "# Correlação de Pearson\n",
        "pearson_correlation_matrix = df[numerical_features].corr(method='pearson')\n",
        "pearson_correlation_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__E4jZDwMr0C"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(11, 8))\n",
        "sns.heatmap(pearson_correlation_matrix, annot=True, fmt=\".2f\",cmap='Dark2',linewidths=0.5)\n",
        "plt.title('Correlação das variáveis numéricas')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osaousiYrTmv"
      },
      "outputs": [],
      "source": [
        "# Features numéricas vs Cancelamento\n",
        "palette = sns.color_palette(\"Set2\")\n",
        "plt.figure(figsize=(18, 25))\n",
        "for i, col in enumerate(numerical_features):\n",
        "    plt.subplot(6, 3, i + 1)\n",
        "    sns.boxplot(x='Cancelamento', y=col, data=df, palette=palette)\n",
        "    plt.title(f'{col} vs Cancelamento')\n",
        "    plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}